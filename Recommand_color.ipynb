{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.imageprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_codis_color_info =  pd.read_csv(\"data/codis_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = df_codis_color_info.filter(regex = \"color1_[RGB]\").values\n",
    "color2 = df_codis_color_info.filter(regex = \"color2_[RGB]\").values\n",
    "color3 = df_codis_color_info.filter(regex = \"color3_[RGB]\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.concatenate([color1, color2], axis = 1)\n",
    "y = color3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_train, X0_test, y_train, y_test = train_test_split(X0, y, test_size = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1114, 6), (2, 6), (1114, 3), (2, 3))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0_train.shape, X0_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change form (sample, timesteps, input_dim)\n",
    "X_train = X0_train.reshape((X0_train.shape[0], 2, 3)) /256\n",
    "X_test = X0_test.reshape((X0_test.shape[0], 2, 3)) /256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change form (sample, timesteps, input_dim)\n",
    "X = X0.reshape((X0.shape[0], 2, 3)) /256\n",
    "y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling(RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(0)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(10, input_shape=(2,3)))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"linear\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-384-cb4928748dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=10000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEFCAYAAAAL/efAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIg6k8BcRcSCFv4iIA/1/+3F2y6Gvo+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x282a0056cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 225.59596231  231.41857335  234.08371467]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3cFpQkEUQFENsQMJZJUOrECyD3Yg\nQhaCm1SU6ixl0sIHwx/hntPAe4vhMpthtmOMsQEIepm9AMAsAghkCSCQJYBAlgACWQIIZAkgkCWA\nQJYAAlmvawzZn25rjHnY9fM4e4VFfr6/Zq+wyMf722ath0bO2P86/O5mr7DI5X5+6Iy5AQJZAghk\nCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWA\nQNZ2rPVrDcCTcQMEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDI+gOYuxVl00b6wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829b5c52e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.72345437  129.03159961  134.94425908]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARxJREFUeJzt3bFpQzEUQFE7ZAd3XiMLZIDUxnWG\nCAbP4DrDeQETUrhXVvjg8GW45yzwXiEuaoS2Y4yxAQh6mb0AwCwCCGQJIJAlgECWAAJZAghkCSCQ\nJYBAlgACWa9rDLn93NcY87D9+2n2Cot8fuxmr7DI5fy1WeuhkTP2v75/32avsMjxenjojLkBAlkC\nCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQ\nJYBA1nas9WsNwJNxAwSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDI\nEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMj6Awb+G2Wup7jCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829b4da358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 242.42732558  243.39593023  245.61598837]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3bFtQjEUQFGI6KJkBCTEHvRpU0ap\n6RiCKRiDkRjFrPAlou9I95wF3iusKzeWt2OMsQEIepu9AMAsAghkCSCQJYBAlgACWQIIZAkgkCWA\nQJYAAlm7NYbsD8c1xrzs9H2evcIit+tl9gqLfH68b9Z6aOSM/a2v+372Cov8Pn5eOmNugECWAAJZ\nAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkLUda/1aA/DPuAECWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkPQHP3BVlgT6UzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d2327b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98.93036623  98.52997208  67.6359008 ]\n",
      "[-138.63491821   37.86972809 -137.7096405 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARhJREFUeJzt3bFtQjEUQFFALJKOgoqCJkOkylBk\nCDZhEiZBIDkrfInoO9I9Z4H3CuvKjeXtGGNsAIJ2sxcAmEUAgSwBBLIEEMgSQCBLAIEsAQSyBBDI\nEkAga7/GkNfzucaYtx1Ph9krLPJ5/pi9wiLX622z1kMjZ+xvfT2+Z6+wyM/98tYZcwMEsgQQyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIGs\n7Vjr1xqAf8YNEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEs\nAQSyBBDIEkAgSwCBLAEEsgQQyBJAIOsXbq8bZYgQcPYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829c14bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 228.9212612   229.31030324  230.06082012]\n",
      "[-92.77224731  33.84046173 -90.6581192 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARZJREFUeJzt3bFtQjEUQFFADECThtCxVcQWpM5S\nkHmYgQmcFb4E+o50z1ngvcK6cmN5O8YYG4Cg3ewFAGYRQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQ\nyNqvMeTndF5jzMvuH4fZKyxy+73PXmGR0+dxs9ZDI2fsva7P79krLHJ5fL10xtwAgSwBBLIEEMgS\nQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgazvW\n+rUG4J9xAwSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCB\nLAEEsgQQyBJAIEsAgSwBBLIEEMj6AyAAF2W/nzglAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829272dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27.72964417  28.16867165  29.4408003 ]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARdJREFUeJzt3bFpA0EQQFGdcT0ObTCqxAhcjXtS\npkCFKLCujlULBzK3hv9eAzPB8tlk2WWMMQ4AQS+zFwCYRQCBLAEEsgQQyBJAIEsAgSwBBLIEEMgS\nQCDrdY8h6/l7jzFPW95+Zq+wyfvH5+wVNlnvv4e9Hho5Y3/rcrzOXmGT0+3rqTPmBghkCSCQJYBA\nlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlnL\n2OvXGoB/xg0QyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwB\nBLIEEMgSQCBLAIEsAQSyBBDIEkAg6wHLahplbtgEPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829388a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 102.08095839  105.14602774   82.76645649]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARxJREFUeJzt3bFtQjEUQFGIMhQdVVZIEbEDA6TJ\nBLRI9CmhT51BGMVZ4UtE30j3nAXeK6wrN5a3Y4yxAQh6mb0AwCwCCGQJIJAlgECWAAJZAghkCSCQ\nJYBAlgACWa9rDLl+n9YY87D92/vsFRb5/DrOXmGRy/m2WeuhkTP2v352v7NXWORw/3jojLkBAlkC\nCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQ\nJYBA1nas9WsNwJNxAwSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDI\nEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMj6AzphGmVO3ZjQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829be91588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 213.24304597  212.95743736  212.06115605]\n",
      "[-92.77240753  33.84047318 -90.65828705]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAQtJREFUeJzt3cEJQjEUAEEVsQsRz1qR2I8VCVqN\npcQWPigG2ZkG8iBhySVkPcYYK4CgzewBAGYRQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyNr+YpF/\neWxy2B9nj7DI43mfPcIip/P5Z3vvjH3XbXebPcIi19flo713AwSyBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgaz1+JffZAC+zA0QyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEs\nAQSyBBDIEkAg6w1m/hplT8lwuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829b27c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44.61550388  60.89767442  76.51782946]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARtJREFUeJzt3bFpQzEUQFE7ZCcP4C5NIO5Myuzk\nxuAl0hlcZYT0HkVZ4YPDl+Ges8B7hbioEdqOMcYGIOhl9gIAswggkCWAQJYAAlkCCGQJIJAlgECW\nAAJZAghkva4x5HS+rDHmYYf3t9krLLL/+Jq9wiK/P9+btR4aOWP/67q7zV5hkc/78aEz5gYIZAkg\nkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECW\nAAJZ27HWrzUAT8YNEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBL\nAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIOsP5aoaZarUQ4wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d35b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 223.19782214  221.73756806  227.9800363 ]\n",
      "[-279.35858154   50.23300934 -282.08111572]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARlJREFUeJzt3bFpQzEUQFHbZAdDwEX4XYqAwRkh\n6xhSewO32SsrKSt8sPkK3HMWeK8QFzVC+zHG2AEEHWYvADCLAAJZAghkCSCQJYBAlgACWQIIZAkg\nkCWAQNbLFkOWj/MWYx72c/uavcIq75/X2Sus8racdls9NHLGnuty/569wirH39eHzpgbIJAlgECW\nAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQII\nZO3HVr/WAPwzboBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQII\nZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZf9mzFWV0D7qSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829c12d5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 218.92608882  207.45923622  195.27644282]\n",
      "[-92.99116516  33.85969162 -90.88270569]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAR1JREFUeJzt3bFtQjEUQFGIUjMGfQbIIhEDMEMG\nSIugzAxILJA+YzCKs8KXiL6R7jkLvFdYV24sb8cYYwMQ9DJ7AYBZBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgSwBBLJe1xhy/DytMeZh1++v2Sss8vtzm73CIvu3981aD42csf913l1mr7DI4f7x0BlzAwSy\nBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgaztWOvXGoAn4wYIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQ9Qct6BplXKA5PQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829c05d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 240.16676185  236.29868646  228.2055968 ]\n",
      "[-107.2638855    35.11362457 -105.52540588]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARlJREFUeJzt3bFpQzEUQFE7eIAULpNJzIcUKT1I\ngrOKp/BcabKIssIHmy/DPWeB9wpxUSO0H2OMHUDQy+wFAGYRQCBLAIEsAQSyBBDIEkAgSwCBLAEE\nsgQQyDpsMeT8edpizN2+lvfZK6yy/Fxnr7DK6/Ftt9VDI2fssf5uH7NXWOXy+33XGXMDBLIEEMgS\nQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCB\nrP3Y6tcagCfjBghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBA\nlgACWQIIZAkgkCWAQJYAAlkCCGQJIJD1D5uDFmX8UMLSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d50d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 210.03590604  213.82181208  219.47248322]\n",
      "[-92.9865799   33.85929108 -90.87800598]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARtJREFUeJzt3cFpQkEUQFEN2VuFq0D6SAsipJMU\noWAlKUBwE9KEpUxa+GD4I9xzGnhvMVxmM8x2jDE2AEEvsxcAmEUAgSwBBLIEEMgSQCBLAIEsAQSy\nBBDIEkAg63WNIR+fX2uMedjv92X2Cotcbz+zV1jk/W2/WeuhkTP2v0678+wVFjneDw+dMTdAIEsA\ngSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSy\nBBDI2o61fq0BeDJugECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZ\nAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAll/1ekaZZDhu1YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f7d94a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 175.14454594  175.22944653  175.97743149]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARVJREFUeJzt3cFpQkEUQFENdpKQCmzkb8VChewS\ncWETljK28MHwR7jnNPDeYrjMZpj9GGPsAII+Zi8AMIsAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBA\n1mGLIZ9f31uMedn9fpu9wip/v9fZK6yyLMtuq4dGztj/uhx/Zq+wyvlxeumMuQECWQIIZAkgkCWA\nQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgEDWfmz1\naw3Am3EDBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEs\nAQSyBBDIEkAgSwCBLAEEsgQQyHoC/0MaZZowa3sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829b3945c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80.11413969  64.67404884  54.49119818]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARtJREFUeJzt3bFpQzEUQFE7ZDNvYbJPBknh1hkg\nYFy6SOPShEzgGZQVPjh8Ge45C7xXiIsaoe0YY2wAgl5mLwAwiwACWQIIZAkgkCWAQJYAAlkCCGQJ\nIJAlgEDW6xpDfr6/1hjzsPvnYfYKi7yfr7NXWOR4umzWemjkjP2v28du9gqLvP3uHzpjboBAlgAC\nWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJ\nIJC1HWv9WgPwZNwAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIE\nEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsv4ABwYfZaP9hYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f897390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 252.64321192  252.51448675  251.6138245 ]\n",
      "[-95.0249939   34.03837585 -92.96925354]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARZJREFUeJzt3TFqAzEQQFFv2NzSEEjpLqT0yQx2\nnyplShe5iHKFBYeV4b93gZlCfNQILWOMcQAIepm9AMAsAghkCSCQJYBAlgACWQIIZAkgkCWAQJYA\nAlnrHkN+vi97jHnY6fM8e4VNbtev2Stssq6vh70eGjlj/+v992P2Cpu83Y8PnTE3QCBLAIEsAQSy\nBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyFrG\nXr/WADwZN0AgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQ\nyBJAIEsAgSwBBLIEEMgSQCBLAIGsP3XmG2Wdt8ZFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d63ec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34.15849338  32.52172292  29.87339176]\n",
      "[-92.7769928   33.84087753 -90.66298676]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARRJREFUeJzt3cFpQkEUQFEVK0sVQdKS2JJoAbpy\nGYUUMmnhg+FP4J7TwHuL4TKbYbZjjLEBCNrNXgBgFgEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIGs\n/RpDHvfzGmPedjydZq+wyPlym73CIt+vn81aD42csb/1cf2cvcIiX8/DW2fMDRDIEkAgSwCBLAEE\nsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLK2Y61f\nawD+GTdAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgS\nQCBLAIEsAQSyBBDIEkAgSwCBrF/USB5lAa8xhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829b47ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 126.80246914  129.74250441  129.11992945]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARlJREFUeJzt3cFJQ0EUQNFE0oerYBn2Eezlg1Vk\npZXERWIfljK28CHhT+Ce08B7i+Eym2H2Y4yxAwh6mb0AwCwCCGQJIJAlgECWAAJZAghkCSCQJYBA\nlgACWYcthrwe37YYc7frz232Cqt8fZ9nr7DK57Lstnpo5Iw91u/7ZfYKq3z8ne46Y26AQJYAAlkC\nCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQ\ntR9b/VoD8GTcAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDI\nEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLL+AX9LGmUWYasLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829fa445c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 117.06516588  135.93056872  162.27037915]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARhJREFUeJzt3bFtQjEUQFFA7JUiFQPQoCg1C1DQ\n0zEgJRJthnBW+BLRd6R7zgLvFdaVG8vbMcbYAATtZi8AMIsAAlkCCGQJIJAlgECWAAJZAghkCSCQ\nJYBA1n6NIa/Hzxpj3vZx+Jy9wiLH82X2Covcr9+btR4aOWN/67a7zl5hka/n6a0z5gYIZAkgkCWA\nQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZ\n27HWrzUA/4wbIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZ\nAghkCSCQJYBAlgACWQIIZAkgkCWAQNYve1caZYf6STYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d7b0b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.6615991   105.96114865   54.51295045]\n",
      "[-92.77427673  33.84063721 -90.6601944 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAR1JREFUeJzt3bFpQzEUQFE7ZAn3XihtSONxDCkD\nbjyBd0hv3GWCzOAJlBU+OHwZ7jkLvFeIixqh7RhjbACCXmYvADCLAAJZAghkCSCQJYBAlgACWQII\nZAkgkCWAQNbrGkOu35c1xjzs8+s8e4VFjrv77BUW2Z9um7UeGjlj/+vt5zB7hUU+ft8fOmNugECW\nAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQII\nZAkgkLUda/1aA/Bk3ACBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEE\nsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSy/gAODBxl1J21qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f795588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 225.46568332  226.30794702  223.11258278]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARtJREFUeJzt3cFpQkEUQFEVKwi4VawgLWSRtQWE\nbCzEImzAmtJBSpm08MHwR7jnNPDeYrjMZpjtGGNsAIJ2sxcAmEUAgSwBBLIEEMgSQCBLAIEsAQSy\nBBDIEkAga7/GkMPbYY0xT3v/uMxeYZHH/TZ7hUVOx/NmrYdGztj/uv58zl5hke/fr6fOmBsgkCWA\nQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZ\nAghkbcdav9YAvBg3QCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEs\nAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgaw//H0VZfLhDOkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d6778d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 161.81294964  161.79856115  166.8057554 ]\n",
      "[-92.77223969  33.84045792 -90.65811157]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARJJREFUeJzt3TFKA0EUgOFd8XxiKSGwpWAt5LgR\nLFLlDOMVAiuzyv99F5hXPH6mGWYdY4wFIOjp6AEAjiKAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQ\n9TzjkK/v+4xjdnt5ez16hId8vn8cPcJDtu20zHpoZMd+1+X2P3bsfN23Y26AQJYAAlkCCGQJIJAl\ngECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQtY5Zv9YA\n/DFugECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBA\nlgACWQIIZAkgkCWAQJYAAlk/Io4bZRecS08AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d5f25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 242.74365704  243.50568679  243.93088364]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARZJREFUeJzt3bFtQjEUQFFAtGQGlI4y2YMGOsQs\nEROxEqM4K3yJ6DvSPWeB9wrryo3l7RhjbACCdrMXAJhFAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIGu/xpDj52mNMW+7Xs6zV1jk8fiZvcIiH4fDZq2HRs7Y3/p+fs1eYZH76/bWGXMDBLIEEMgSQCBL\nAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBrO1Y\n69cagH/GDRDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEE\nsgQQyBJAIEsAgSwBBLIEEMgSQCDrF+DsFWUmCaBsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f72b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 158.52694851  159.99499098  162.6537768 ]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3bFpQzEUQFE7ZDK7DumDMSTjuPUU\nniCFG1epsoNHUVb44PBluOcs8F4hLmqEtmOMsQEIepm9AMAsAghkCSCQJYBAlgACWQIIZAkgkCWA\nQJYAAlmvawx5f9uvMeZhp/Nl9gqL/Ny+Z6+wyNfncbPWQyNn7H/97q6zV1jkcP946Iy5AQJZAghk\nCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWA\nQNZ2rPVrDcCTcQMEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDI+gNKIhplAZu69AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829d7a8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 237.52037915  239.45402844  240.92890995]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3cFNQkEUQFEwFgBxo4Q2bMZAF2zs\nhj01WIsFUMTYwk8wf0juOQ28t5jczGYy2zHG2AAEvcxeAGAWAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIEsAgazXNYZ8HI5rjHnY+/k6e4VFfr4/Z6+wyNt+t1nroZEz9r8ut/vsFRY5/X49dMbcAIEsAQSy\nBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJA\nIGs71vq1BuDJuAECWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkCWAQJYAAlkCCGQJIJAlgECWAAJZAghk/QHbJBZl0PmO8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f3a74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 242.96136457  241.75297986  239.02671599]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3bFtQjEUQFGIqBNlPURJTZMqddbJ\nCIiGBdiAIRjArPAlou9I95wF3iusKzeWt2OMsQEIepu9AMAsAghkCSCQJYBAlgACWQIIZAkgkCWA\nQJYAAlm7NYZcfo5rjHnZ9+9t9gqLnK/n2Sss8v7xuVnroZEz9rdOj6/ZKyxyuO9fOmNugECWAAJZ\nAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkLUda/1aA/DPuAECWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkg\nkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkPQFN3xtl1HIXQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829e2a35c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 229.68225806  231.31989247  232.04247312]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARhJREFUeJzt3VFNA0EUQNEuqQiWiuCjMlBQQvCA\nB1RUDFYqZWphkzY7JPccA+99TG7mZzLLGGMcAIJeZi8AMIsAAlkCCGQJIJAlgECWAAJZAghkCSCQ\nJYBA1nGPIev6tseYh50/vmevsMn192f2Cpuc1tfDXg+NnLHnuvy9z15hk6/b50NnzA0QyBJAIEsA\ngSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEsAQSy\nlrHXrzUA/4wbIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZ\nAghkCSCQJYBAlgACWQIIZAkgkCWAQNYdWwwVZaT4KpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829f4e7400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 219.29118329  224.39814385  233.18213457]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARtJREFUeJzt3bFpQzEUQFE7ZAFXbtMEsoBLQ1K7\ntZvgxjtkoizmUZQVPjh8Ge45C7xXiIsaoe0YY2wAgl5mLwAwiwACWQIIZAkgkCWAQJYAAlkCCGQJ\nIJAlgEDW6xpDPg5fa4x52OfpMnuFRX5u59krLPL+tt+s9dDIGftfx9/d7BUWud6/HzpjboBAlgAC\nWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJ\nIJC1HWv9WgPwZNwAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIE\nEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsv4ALRsVZZTZ3LoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829e17f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 205.18286626  211.50567577  225.29797801]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARpJREFUeJzt3bFpA0EQQFGdcB+uwIFwrEaMUAWq\nwH24C6eux10oOli1cCBza/jvNTATLJ9Nll3GGOMAEHScvQDALAIIZAkgkCWAQJYAAlkCCGQJIJAl\ngECWAAJZL3sMWdd1jzFPO3/+zF5hk6/rafYKm7y/vR72emjkjP2t2/d99gqbXH4/njpjboBAlgAC\nWQIIZAkgkCWAQJYAAlkCCGQJIJAlgECWAAJZAghkCSCQJYBAlgACWQIIZAkgkCWAQJYAAlkCCGQJ\nIJC1jL1+rQH4Z9wAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIE\nEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsh7yDRxldfB4bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829db37128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 236.1466285   237.09160305  237.71851145]\n",
      "[-92.77222443  33.84045792 -90.65808868]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAA2CAYAAAC2nEDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAARhJREFUeJzt3bFtQjEUQFFAbEBmQEpFm1SUFGyA\nmCQVE7ESozgrfInoO9I9Z4H3CuvKjeXtGGNsAIJ2sxcAmEUAgSwBBLIEEMgSQCBLAIEsAQSyBBDI\nEkAga7/GkOPneY0xb7tcT7NXWOTx85i9wiIfh8NmrYdGztjf+np+z15hkfvr9tYZcwMEsgQQyBJA\nIEsAgSwBBLIEEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIGs\n7Vjr1xqAf8YNEMgSQCBLAIEsAQSyBBDIEkAgSwCBLAEEsgQQyBJAIEsAgSwBBLIEEMgSQCBLAIEs\nAQSyBBDIEkAgSwCBLAEEsgQQyBJAIOsX8KwVZRsiaz4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2829e1c25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(30):\n",
    "    input_color = np.vstack([color1[idx], color2[idx]])[np.newaxis, :, :]\n",
    "    color_3_pre = model.predict(input_color)[0]\n",
    "\n",
    "    true = [color1[idx], color2[idx], color3[idx]]\n",
    "    predict = [color1[idx], color2[idx], color_3_pre]\n",
    "    print(color3[idx])\n",
    "    print(color_3_pre)\n",
    "    bar_true = plot_colors([0.33, 0.33, 0.33], true, h=50, w=300)\n",
    "    bar_predict = plot_colors([0.33, 0.33, 0.33], predict, h=50, w=300)\n",
    "    \n",
    "    plt.figure(figsize = (5, 1))  \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(bar_true)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(bar_predict)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374, 6), (374, 3))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change form\n",
    "X0.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(0)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_dim=6, activation = \"relu\"))\n",
    "model1.add(Dense(3, activation = \"linear\"))\n",
    "model1.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X0/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 166.2635\n",
      "Epoch 2/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 165.8727\n",
      "Epoch 3/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 163.1813\n",
      "Epoch 4/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 165.1946\n",
      "Epoch 5/1000\n",
      "374/374 [==============================] - 0s 249us/step - loss: 179.0050\n",
      "Epoch 6/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 184.5179\n",
      "Epoch 7/1000\n",
      "374/374 [==============================] - 0s 257us/step - loss: 165.8378\n",
      "Epoch 8/1000\n",
      "374/374 [==============================] - 0s 229us/step - loss: 166.6441\n",
      "Epoch 9/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 168.6259\n",
      "Epoch 10/1000\n",
      "374/374 [==============================] - 0s 175us/step - loss: 165.0675\n",
      "Epoch 11/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 167.7074\n",
      "Epoch 12/1000\n",
      "374/374 [==============================] - 0s 291us/step - loss: 172.1106\n",
      "Epoch 13/1000\n",
      "374/374 [==============================] - 0s 239us/step - loss: 163.2311\n",
      "Epoch 14/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 164.4689\n",
      "Epoch 15/1000\n",
      "374/374 [==============================] - 0s 159us/step - loss: 171.7429\n",
      "Epoch 16/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 174.9350\n",
      "Epoch 17/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 173.4000\n",
      "Epoch 18/1000\n",
      "374/374 [==============================] - 0s 143us/step - loss: 167.1091\n",
      "Epoch 19/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 168.3707\n",
      "Epoch 20/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 164.8978\n",
      "Epoch 21/1000\n",
      "374/374 [==============================] - 0s 126us/step - loss: 167.9668\n",
      "Epoch 22/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 179.0201\n",
      "Epoch 23/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 182.8142\n",
      "Epoch 24/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 180.9774\n",
      "Epoch 25/1000\n",
      "374/374 [==============================] - 0s 285us/step - loss: 169.8263\n",
      "Epoch 26/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 164.5094\n",
      "Epoch 27/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 171.9338\n",
      "Epoch 28/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 164.4191\n",
      "Epoch 29/1000\n",
      "374/374 [==============================] - 0s 237us/step - loss: 190.1047\n",
      "Epoch 30/1000\n",
      "374/374 [==============================] - 0s 164us/step - loss: 174.3877\n",
      "Epoch 31/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 171.7748\n",
      "Epoch 32/1000\n",
      "374/374 [==============================] - 0s 316us/step - loss: 168.4889\n",
      "Epoch 33/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 165.7472\n",
      "Epoch 34/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 164.9693\n",
      "Epoch 35/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 165.7551\n",
      "Epoch 36/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 163.3467\n",
      "Epoch 37/1000\n",
      "374/374 [==============================] - 0s 258us/step - loss: 170.9278\n",
      "Epoch 38/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 166.4827\n",
      "Epoch 39/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 164.3770\n",
      "Epoch 40/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 162.5384\n",
      "Epoch 41/1000\n",
      "374/374 [==============================] - 0s 274us/step - loss: 166.8765\n",
      "Epoch 42/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 170.4701\n",
      "Epoch 43/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 170.0178\n",
      "Epoch 44/1000\n",
      "374/374 [==============================] - 0s 132us/step - loss: 165.7124\n",
      "Epoch 45/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 169.7818\n",
      "Epoch 46/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 171.8511\n",
      "Epoch 47/1000\n",
      "374/374 [==============================] - 0s 158us/step - loss: 173.5137\n",
      "Epoch 48/1000\n",
      "374/374 [==============================] - 0s 136us/step - loss: 169.0566\n",
      "Epoch 49/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 163.2012\n",
      "Epoch 50/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 164.8232\n",
      "Epoch 51/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 167.9056\n",
      "Epoch 52/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 171.0739\n",
      "Epoch 53/1000\n",
      "374/374 [==============================] - 0s 318us/step - loss: 175.2365\n",
      "Epoch 54/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 193.3308\n",
      "Epoch 55/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 189.4694\n",
      "Epoch 56/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 168.2822\n",
      "Epoch 57/1000\n",
      "374/374 [==============================] - 0s 219us/step - loss: 163.2363\n",
      "Epoch 58/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 167.0205\n",
      "Epoch 59/1000\n",
      "374/374 [==============================] - 0s 241us/step - loss: 169.7582\n",
      "Epoch 60/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 169.6918\n",
      "Epoch 61/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 165.5882\n",
      "Epoch 62/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 169.7388\n",
      "Epoch 63/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 170.4607\n",
      "Epoch 64/1000\n",
      "374/374 [==============================] - 0s 271us/step - loss: 164.4430\n",
      "Epoch 65/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 168.8145\n",
      "Epoch 66/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 166.2594\n",
      "Epoch 67/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 162.6803\n",
      "Epoch 68/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 162.9129\n",
      "Epoch 69/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 164.7237\n",
      "Epoch 70/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 167.3023\n",
      "Epoch 71/1000\n",
      "374/374 [==============================] - 0s 135us/step - loss: 165.2603\n",
      "Epoch 72/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 161.6664\n",
      "Epoch 73/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 167.5420\n",
      "Epoch 74/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 167.8314\n",
      "Epoch 75/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 173.2941\n",
      "Epoch 76/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 172.1671\n",
      "Epoch 77/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 167.7340\n",
      "Epoch 78/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 165.7214\n",
      "Epoch 79/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 165.8952\n",
      "Epoch 80/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 178.5100\n",
      "Epoch 81/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 171.8933\n",
      "Epoch 82/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 164.0249\n",
      "Epoch 83/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 166.5964\n",
      "Epoch 84/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 165.1361\n",
      "Epoch 85/1000\n",
      "374/374 [==============================] - 0s 305us/step - loss: 170.5142\n",
      "Epoch 86/1000\n",
      "374/374 [==============================] - 0s 250us/step - loss: 177.6760\n",
      "Epoch 87/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 175.7791\n",
      "Epoch 88/1000\n",
      "374/374 [==============================] - 0s 110us/step - loss: 173.1096\n",
      "Epoch 89/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 178.6056\n",
      "Epoch 90/1000\n",
      "374/374 [==============================] - 0s 227us/step - loss: 172.0567\n",
      "Epoch 91/1000\n",
      "374/374 [==============================] - 0s 272us/step - loss: 164.9984\n",
      "Epoch 92/1000\n",
      "374/374 [==============================] - 0s 105us/step - loss: 174.0029\n",
      "Epoch 93/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 168.3503\n",
      "Epoch 94/1000\n",
      "374/374 [==============================] - 0s 189us/step - loss: 173.8303\n",
      "Epoch 95/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 168.4133\n",
      "Epoch 96/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 162.0581\n",
      "Epoch 97/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 163.9047\n",
      "Epoch 98/1000\n",
      "374/374 [==============================] - 0s 143us/step - loss: 163.1103\n",
      "Epoch 99/1000\n",
      "374/374 [==============================] - 0s 132us/step - loss: 166.5870\n",
      "Epoch 100/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 163.7138\n",
      "Epoch 101/1000\n",
      "374/374 [==============================] - 0s 253us/step - loss: 162.9161\n",
      "Epoch 102/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 166.4751\n",
      "Epoch 103/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 174.0731\n",
      "Epoch 104/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 169.0906\n",
      "Epoch 105/1000\n",
      "374/374 [==============================] - 0s 170us/step - loss: 165.3862\n",
      "Epoch 106/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 166.6106\n",
      "Epoch 107/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 166.5247\n",
      "Epoch 108/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 179.7630\n",
      "Epoch 109/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 175.8780\n",
      "Epoch 110/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 164.1545\n",
      "Epoch 111/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 165.6604\n",
      "Epoch 112/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 165.2755\n",
      "Epoch 113/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 163.2543\n",
      "Epoch 114/1000\n",
      "374/374 [==============================] - 0s 241us/step - loss: 163.0100\n",
      "Epoch 115/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 164.9580\n",
      "Epoch 116/1000\n",
      "374/374 [==============================] - 0s 143us/step - loss: 162.6035\n",
      "Epoch 117/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 162.7359\n",
      "Epoch 118/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 164.7857\n",
      "Epoch 119/1000\n",
      "374/374 [==============================] - 0s 120us/step - loss: 163.3361\n",
      "Epoch 120/1000\n",
      "374/374 [==============================] - 0s 279us/step - loss: 167.5660\n",
      "Epoch 121/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 162.9793\n",
      "Epoch 122/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 164.2037\n",
      "Epoch 123/1000\n",
      "374/374 [==============================] - 0s 106us/step - loss: 164.2121\n",
      "Epoch 124/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 163.7091\n",
      "Epoch 125/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 168.3577\n",
      "Epoch 126/1000\n",
      "374/374 [==============================] - 0s 111us/step - loss: 166.3146\n",
      "Epoch 127/1000\n",
      "374/374 [==============================] - 0s 116us/step - loss: 163.6489\n",
      "Epoch 128/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 162.7009\n",
      "Epoch 129/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 161.8087\n",
      "Epoch 130/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 163.7139\n",
      "Epoch 131/1000\n",
      "374/374 [==============================] - 0s 408us/step - loss: 168.0626\n",
      "Epoch 132/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 168.8009\n",
      "Epoch 133/1000\n",
      "374/374 [==============================] - 0s 286us/step - loss: 173.0963\n",
      "Epoch 134/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 178.7123\n",
      "Epoch 135/1000\n",
      "374/374 [==============================] - 0s 239us/step - loss: 178.2402\n",
      "Epoch 136/1000\n",
      "374/374 [==============================] - 0s 217us/step - loss: 174.2337\n",
      "Epoch 137/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 168.4730\n",
      "Epoch 138/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 168.0072\n",
      "Epoch 139/1000\n",
      "374/374 [==============================] - 0s 174us/step - loss: 164.3317\n",
      "Epoch 140/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 175.8983\n",
      "Epoch 141/1000\n",
      "374/374 [==============================] - 0s 181us/step - loss: 173.2732\n",
      "Epoch 142/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 168.4779\n",
      "Epoch 143/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 164.7979\n",
      "Epoch 144/1000\n",
      "374/374 [==============================] - 0s 136us/step - loss: 164.9824\n",
      "Epoch 145/1000\n",
      "374/374 [==============================] - 0s 116us/step - loss: 174.1559\n",
      "Epoch 146/1000\n",
      "374/374 [==============================] - 0s 111us/step - loss: 170.2945\n",
      "Epoch 147/1000\n",
      "374/374 [==============================] - 0s 128us/step - loss: 162.1391\n",
      "Epoch 148/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 165.1000\n",
      "Epoch 149/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 161.0882\n",
      "Epoch 150/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 161.8339\n",
      "Epoch 151/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 166.2592\n",
      "Epoch 152/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 167.3188\n",
      "Epoch 153/1000\n",
      "374/374 [==============================] - 0s 150us/step - loss: 163.1819\n",
      "Epoch 154/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 163.2586\n",
      "Epoch 155/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 167.9777\n",
      "Epoch 156/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 190.1291\n",
      "Epoch 157/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 180.5189\n",
      "Epoch 158/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 166.9657\n",
      "Epoch 159/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 169.8144\n",
      "Epoch 160/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 165.6352\n",
      "Epoch 161/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 162.9028\n",
      "Epoch 162/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 161.1853\n",
      "Epoch 163/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 165.0065\n",
      "Epoch 164/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 162.8160\n",
      "Epoch 165/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 168.9518\n",
      "Epoch 166/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 169.8318\n",
      "Epoch 167/1000\n",
      "374/374 [==============================] - 0s 175us/step - loss: 174.3267\n",
      "Epoch 168/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 176.4506\n",
      "Epoch 169/1000\n",
      "374/374 [==============================] - 0s 258us/step - loss: 170.2067\n",
      "Epoch 170/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 166.3579\n",
      "Epoch 171/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 166.0109\n",
      "Epoch 172/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 172.7445\n",
      "Epoch 173/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 180.3682\n",
      "Epoch 174/1000\n",
      "374/374 [==============================] - 0s 109us/step - loss: 173.8892\n",
      "Epoch 175/1000\n",
      "374/374 [==============================] - 0s 111us/step - loss: 166.4737\n",
      "Epoch 176/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 175.5087\n",
      "Epoch 177/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 169.8408\n",
      "Epoch 178/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 170.5433\n",
      "Epoch 179/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 164.5718\n",
      "Epoch 180/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 162.9621\n",
      "Epoch 181/1000\n",
      "374/374 [==============================] - 0s 132us/step - loss: 166.7015\n",
      "Epoch 182/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 169.2416\n",
      "Epoch 183/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 165.7268\n",
      "Epoch 184/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 165.5113\n",
      "Epoch 185/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 166.4339\n",
      "Epoch 186/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 163.4366\n",
      "Epoch 187/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 164.2549\n",
      "Epoch 188/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 161.9712\n",
      "Epoch 189/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 164.7324\n",
      "Epoch 190/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 166.1527\n",
      "Epoch 191/1000\n",
      "374/374 [==============================] - 0s 217us/step - loss: 165.9548\n",
      "Epoch 192/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 165.0449\n",
      "Epoch 193/1000\n",
      "374/374 [==============================] - 0s 267us/step - loss: 173.0721\n",
      "Epoch 194/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 164.8712\n",
      "Epoch 195/1000\n",
      "374/374 [==============================] - 0s 74us/step - loss: 163.3560\n",
      "Epoch 196/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 165.3644\n",
      "Epoch 197/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 169.8699\n",
      "Epoch 198/1000\n",
      "374/374 [==============================] - 0s 250us/step - loss: 166.7629\n",
      "Epoch 199/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 170.8721\n",
      "Epoch 200/1000\n",
      "374/374 [==============================] - 0s 227us/step - loss: 167.1367\n",
      "Epoch 201/1000\n",
      "374/374 [==============================] - 0s 154us/step - loss: 167.4912\n",
      "Epoch 202/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 165.5167\n",
      "Epoch 203/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 163.3164\n",
      "Epoch 204/1000\n",
      "374/374 [==============================] - 0s 115us/step - loss: 165.5751\n",
      "Epoch 205/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 163.0563\n",
      "Epoch 206/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 164.5870\n",
      "Epoch 207/1000\n",
      "374/374 [==============================] - 0s 204us/step - loss: 164.2930\n",
      "Epoch 208/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 167.4589\n",
      "Epoch 209/1000\n",
      "374/374 [==============================] - 0s 128us/step - loss: 168.4297\n",
      "Epoch 210/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 166.3795\n",
      "Epoch 211/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 166.5761\n",
      "Epoch 212/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 170.6415\n",
      "Epoch 213/1000\n",
      "374/374 [==============================] - 0s 144us/step - loss: 166.7421\n",
      "Epoch 214/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 165.2669\n",
      "Epoch 215/1000\n",
      "374/374 [==============================] - 0s 141us/step - loss: 167.8729\n",
      "Epoch 216/1000\n",
      "374/374 [==============================] - 0s 364us/step - loss: 161.9204\n",
      "Epoch 217/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 165.8998\n",
      "Epoch 218/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 160.7627\n",
      "Epoch 219/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 164.7368\n",
      "Epoch 220/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 165.1111\n",
      "Epoch 221/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 169.7188\n",
      "Epoch 222/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 163.7369\n",
      "Epoch 223/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 165.2364\n",
      "Epoch 224/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 165.9482\n",
      "Epoch 225/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 162.2485\n",
      "Epoch 226/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 165.3981\n",
      "Epoch 227/1000\n",
      "374/374 [==============================] - 0s 196us/step - loss: 163.8194\n",
      "Epoch 228/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 161.4664\n",
      "Epoch 229/1000\n",
      "374/374 [==============================] - 0s 251us/step - loss: 164.3571\n",
      "Epoch 230/1000\n",
      "374/374 [==============================] - 0s 150us/step - loss: 167.0898\n",
      "Epoch 231/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 163.0559\n",
      "Epoch 232/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 167.2800\n",
      "Epoch 233/1000\n",
      "374/374 [==============================] - 0s 151us/step - loss: 170.3170\n",
      "Epoch 234/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 164.9236\n",
      "Epoch 235/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 161.6996\n",
      "Epoch 236/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 162.3184\n",
      "Epoch 237/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 166.4854\n",
      "Epoch 238/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 167.3225\n",
      "Epoch 239/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 163.2270\n",
      "Epoch 240/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 180.1362\n",
      "Epoch 241/1000\n",
      "374/374 [==============================] - 0s 243us/step - loss: 166.0857\n",
      "Epoch 242/1000\n",
      "374/374 [==============================] - 0s 385us/step - loss: 164.0222\n",
      "Epoch 243/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 161.4469\n",
      "Epoch 244/1000\n",
      "374/374 [==============================] - 0s 192us/step - loss: 163.3558\n",
      "Epoch 245/1000\n",
      "374/374 [==============================] - 0s 193us/step - loss: 169.8145\n",
      "Epoch 246/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 166.4492\n",
      "Epoch 247/1000\n",
      "374/374 [==============================] - 0s 275us/step - loss: 162.8463\n",
      "Epoch 248/1000\n",
      "374/374 [==============================] - 0s 239us/step - loss: 168.4235\n",
      "Epoch 249/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 166.9275\n",
      "Epoch 250/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 164.1985\n",
      "Epoch 251/1000\n",
      "374/374 [==============================] - 0s 285us/step - loss: 165.8348\n",
      "Epoch 252/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 166.1174\n",
      "Epoch 253/1000\n",
      "374/374 [==============================] - 0s 196us/step - loss: 164.4917\n",
      "Epoch 254/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 186.4251\n",
      "Epoch 255/1000\n",
      "374/374 [==============================] - 0s 128us/step - loss: 183.8090\n",
      "Epoch 256/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 183.7255\n",
      "Epoch 257/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 174.9768\n",
      "Epoch 258/1000\n",
      "374/374 [==============================] - 0s 218us/step - loss: 167.7544\n",
      "Epoch 259/1000\n",
      "374/374 [==============================] - 0s 224us/step - loss: 169.0507\n",
      "Epoch 260/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 166.9887\n",
      "Epoch 261/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 166.5900\n",
      "Epoch 262/1000\n",
      "374/374 [==============================] - 0s 249us/step - loss: 165.4093\n",
      "Epoch 263/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 168.1806\n",
      "Epoch 264/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 168.7381\n",
      "Epoch 265/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 168.1281\n",
      "Epoch 266/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 164.9348\n",
      "Epoch 267/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 173.9097\n",
      "Epoch 268/1000\n",
      "374/374 [==============================] - 0s 172us/step - loss: 169.5160\n",
      "Epoch 269/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 162.4374\n",
      "Epoch 270/1000\n",
      "374/374 [==============================] - 0s 261us/step - loss: 165.6327\n",
      "Epoch 271/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 164.4083\n",
      "Epoch 272/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 160.1599\n",
      "Epoch 273/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 162.4336\n",
      "Epoch 274/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 161.7357\n",
      "Epoch 275/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 161.6769\n",
      "Epoch 276/1000\n",
      "374/374 [==============================] - 0s 78us/step - loss: 161.9069\n",
      "Epoch 277/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 161.7975\n",
      "Epoch 278/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 165.8849\n",
      "Epoch 279/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 166.1425\n",
      "Epoch 280/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 166.7674\n",
      "Epoch 281/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 163.4156\n",
      "Epoch 282/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 163.2528\n",
      "Epoch 283/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 159.0553\n",
      "Epoch 284/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 165.6588\n",
      "Epoch 285/1000\n",
      "374/374 [==============================] - 0s 168us/step - loss: 167.7171\n",
      "Epoch 286/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 165.7039\n",
      "Epoch 287/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 162.3796\n",
      "Epoch 288/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 169.3875\n",
      "Epoch 289/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 167.6593\n",
      "Epoch 290/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 164.9393\n",
      "Epoch 291/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 164.0883\n",
      "Epoch 292/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 164.8322\n",
      "Epoch 293/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 165.3526\n",
      "Epoch 294/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 166.5613\n",
      "Epoch 295/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 163.7322\n",
      "Epoch 296/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 160.5294\n",
      "Epoch 297/1000\n",
      "374/374 [==============================] - 0s 250us/step - loss: 177.4559\n",
      "Epoch 298/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 163.5921\n",
      "Epoch 299/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 163.0064\n",
      "Epoch 300/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 164.6655\n",
      "Epoch 301/1000\n",
      "374/374 [==============================] - 0s 126us/step - loss: 162.3926\n",
      "Epoch 302/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 159.6286\n",
      "Epoch 303/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 162.7775\n",
      "Epoch 304/1000\n",
      "374/374 [==============================] - 0s 253us/step - loss: 171.1019\n",
      "Epoch 305/1000\n",
      "374/374 [==============================] - 0s 127us/step - loss: 162.8415\n",
      "Epoch 306/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 167.4334\n",
      "Epoch 307/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 164.5390\n",
      "Epoch 308/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 162.4552\n",
      "Epoch 309/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 161.4809\n",
      "Epoch 310/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 163.3553\n",
      "Epoch 311/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 166.6825\n",
      "Epoch 312/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 161.7077\n",
      "Epoch 313/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 177.9341\n",
      "Epoch 314/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 172.5635\n",
      "Epoch 315/1000\n",
      "374/374 [==============================] - 0s 75us/step - loss: 165.2041\n",
      "Epoch 316/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 170.6663\n",
      "Epoch 317/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 163.1694\n",
      "Epoch 318/1000\n",
      "374/374 [==============================] - 0s 185us/step - loss: 161.3080\n",
      "Epoch 319/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 166.1772\n",
      "Epoch 320/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 170.2855\n",
      "Epoch 321/1000\n",
      "374/374 [==============================] - 0s 175us/step - loss: 175.5179\n",
      "Epoch 322/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 171.6920\n",
      "Epoch 323/1000\n",
      "374/374 [==============================] - 0s 218us/step - loss: 167.7586\n",
      "Epoch 324/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 165.2677\n",
      "Epoch 325/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 166.5432\n",
      "Epoch 326/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 166.4152\n",
      "Epoch 327/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 164.6794\n",
      "Epoch 328/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 160.0741\n",
      "Epoch 329/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 162.8088\n",
      "Epoch 330/1000\n",
      "374/374 [==============================] - 0s 170us/step - loss: 162.6436\n",
      "Epoch 331/1000\n",
      "374/374 [==============================] - 0s 188us/step - loss: 163.6950\n",
      "Epoch 332/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 160.5832\n",
      "Epoch 333/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 168.0441\n",
      "Epoch 334/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 167.4782\n",
      "Epoch 335/1000\n",
      "374/374 [==============================] - 0s 97us/step - loss: 162.3767\n",
      "Epoch 336/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 164.9035\n",
      "Epoch 337/1000\n",
      "374/374 [==============================] - 0s 144us/step - loss: 168.6068\n",
      "Epoch 338/1000\n",
      "374/374 [==============================] - 0s 127us/step - loss: 163.7482\n",
      "Epoch 339/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 175.0242\n",
      "Epoch 340/1000\n",
      "374/374 [==============================] - 0s 194us/step - loss: 163.9312\n",
      "Epoch 341/1000\n",
      "374/374 [==============================] - 0s 251us/step - loss: 167.8629\n",
      "Epoch 342/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 169.1214\n",
      "Epoch 343/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 167.8727\n",
      "Epoch 344/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 165.9791\n",
      "Epoch 345/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 164.3995\n",
      "Epoch 346/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 163.0293\n",
      "Epoch 347/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 163.5981\n",
      "Epoch 348/1000\n",
      "374/374 [==============================] - 0s 357us/step - loss: 161.1171\n",
      "Epoch 349/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 164.3555\n",
      "Epoch 350/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 170.9154\n",
      "Epoch 351/1000\n",
      "374/374 [==============================] - 0s 136us/step - loss: 165.7591\n",
      "Epoch 352/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 160.3168\n",
      "Epoch 353/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 163.5732\n",
      "Epoch 354/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 164.4963\n",
      "Epoch 355/1000\n",
      "374/374 [==============================] - 0s 137us/step - loss: 165.7560\n",
      "Epoch 356/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 171.3282\n",
      "Epoch 357/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 164.5385\n",
      "Epoch 358/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 161.7920\n",
      "Epoch 359/1000\n",
      "374/374 [==============================] - 0s 116us/step - loss: 171.1302\n",
      "Epoch 360/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 168.2547\n",
      "Epoch 361/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 165.3945\n",
      "Epoch 362/1000\n",
      "374/374 [==============================] - 0s 293us/step - loss: 166.5201\n",
      "Epoch 363/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 161.8691\n",
      "Epoch 364/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 160.3216\n",
      "Epoch 365/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 168.8750\n",
      "Epoch 366/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 165.6989\n",
      "Epoch 367/1000\n",
      "374/374 [==============================] - 0s 140us/step - loss: 163.0691\n",
      "Epoch 368/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 162.5203\n",
      "Epoch 369/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 165.9498\n",
      "Epoch 370/1000\n",
      "374/374 [==============================] - 0s 132us/step - loss: 172.2250\n",
      "Epoch 371/1000\n",
      "374/374 [==============================] - 0s 175us/step - loss: 176.9333\n",
      "Epoch 372/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 173.6382\n",
      "Epoch 373/1000\n",
      "374/374 [==============================] - 0s 299us/step - loss: 161.1933\n",
      "Epoch 374/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 158.4428\n",
      "Epoch 375/1000\n",
      "374/374 [==============================] - 0s 286us/step - loss: 166.8151\n",
      "Epoch 376/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 161.5522\n",
      "Epoch 377/1000\n",
      "374/374 [==============================] - 0s 172us/step - loss: 160.6224\n",
      "Epoch 378/1000\n",
      "374/374 [==============================] - 0s 164us/step - loss: 172.6864\n",
      "Epoch 379/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 160.2267\n",
      "Epoch 380/1000\n",
      "374/374 [==============================] - 0s 265us/step - loss: 168.4267\n",
      "Epoch 381/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 161.3283\n",
      "Epoch 382/1000\n",
      "374/374 [==============================] - 0s 210us/step - loss: 169.3397\n",
      "Epoch 383/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 169.5620\n",
      "Epoch 384/1000\n",
      "374/374 [==============================] - 0s 255us/step - loss: 160.8887\n",
      "Epoch 385/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 162.4300\n",
      "Epoch 386/1000\n",
      "374/374 [==============================] - 0s 202us/step - loss: 170.9372\n",
      "Epoch 387/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 174.8898\n",
      "Epoch 388/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 170.0652\n",
      "Epoch 389/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 173.3728\n",
      "Epoch 390/1000\n",
      "374/374 [==============================] - 0s 314us/step - loss: 172.6416\n",
      "Epoch 391/1000\n",
      "374/374 [==============================] - 0s 251us/step - loss: 168.1875\n",
      "Epoch 392/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 165.6524\n",
      "Epoch 393/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 167.1293\n",
      "Epoch 394/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 166.9782\n",
      "Epoch 395/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 167.2538\n",
      "Epoch 396/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 164.6573\n",
      "Epoch 397/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 163.5780\n",
      "Epoch 398/1000\n",
      "374/374 [==============================] - 0s 210us/step - loss: 163.1334\n",
      "Epoch 399/1000\n",
      "374/374 [==============================] - 0s 250us/step - loss: 165.0578\n",
      "Epoch 400/1000\n",
      "374/374 [==============================] - 0s 233us/step - loss: 170.3397\n",
      "Epoch 401/1000\n",
      "374/374 [==============================] - 0s 270us/step - loss: 162.9312\n",
      "Epoch 402/1000\n",
      "374/374 [==============================] - 0s 329us/step - loss: 161.7715\n",
      "Epoch 403/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 163.9431\n",
      "Epoch 404/1000\n",
      "374/374 [==============================] - 0s 333us/step - loss: 160.1768\n",
      "Epoch 405/1000\n",
      "374/374 [==============================] - 0s 260us/step - loss: 164.8971\n",
      "Epoch 406/1000\n",
      "374/374 [==============================] - 0s 250us/step - loss: 187.1492\n",
      "Epoch 407/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 199.3134\n",
      "Epoch 408/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 175.2292\n",
      "Epoch 409/1000\n",
      "374/374 [==============================] - 0s 237us/step - loss: 172.1431\n",
      "Epoch 410/1000\n",
      "374/374 [==============================] - 0s 342us/step - loss: 159.3721\n",
      "Epoch 411/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 160.8604\n",
      "Epoch 412/1000\n",
      "374/374 [==============================] - 0s 188us/step - loss: 161.2477\n",
      "Epoch 413/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 159.1494\n",
      "Epoch 414/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 160.8867\n",
      "Epoch 415/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 171.9018\n",
      "Epoch 416/1000\n",
      "374/374 [==============================] - 0s 256us/step - loss: 186.9266\n",
      "Epoch 417/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 169.9642\n",
      "Epoch 418/1000\n",
      "374/374 [==============================] - 0s 227us/step - loss: 171.5227\n",
      "Epoch 419/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 166.3524\n",
      "Epoch 420/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 159.9928\n",
      "Epoch 421/1000\n",
      "374/374 [==============================] - 0s 330us/step - loss: 166.0819\n",
      "Epoch 422/1000\n",
      "374/374 [==============================] - 0s 314us/step - loss: 160.5869\n",
      "Epoch 423/1000\n",
      "374/374 [==============================] - 0s 259us/step - loss: 167.4438\n",
      "Epoch 424/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 164.8896\n",
      "Epoch 425/1000\n",
      "374/374 [==============================] - 0s 306us/step - loss: 162.9399\n",
      "Epoch 426/1000\n",
      "374/374 [==============================] - 0s 227us/step - loss: 162.0674\n",
      "Epoch 427/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 166.8045\n",
      "Epoch 428/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 160.4759\n",
      "Epoch 429/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 163.8018\n",
      "Epoch 430/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 163.4590\n",
      "Epoch 431/1000\n",
      "374/374 [==============================] - 0s 255us/step - loss: 168.3564\n",
      "Epoch 432/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 168.9618\n",
      "Epoch 433/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 161.9193\n",
      "Epoch 434/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 174.6825\n",
      "Epoch 435/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 160.8460\n",
      "Epoch 436/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 162.5146\n",
      "Epoch 437/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 168.1401\n",
      "Epoch 438/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 171.4343\n",
      "Epoch 439/1000\n",
      "374/374 [==============================] - 0s 174us/step - loss: 161.4899\n",
      "Epoch 440/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 161.7846\n",
      "Epoch 441/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 161.0111\n",
      "Epoch 442/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 165.2056\n",
      "Epoch 443/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 164.0022\n",
      "Epoch 444/1000\n",
      "374/374 [==============================] - 0s 194us/step - loss: 163.7036\n",
      "Epoch 445/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 160.6505\n",
      "Epoch 446/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 161.3167\n",
      "Epoch 447/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 161.0564\n",
      "Epoch 448/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 161.2697\n",
      "Epoch 449/1000\n",
      "374/374 [==============================] - 0s 236us/step - loss: 167.1115\n",
      "Epoch 450/1000\n",
      "374/374 [==============================] - 0s 354us/step - loss: 160.6300\n",
      "Epoch 451/1000\n",
      "374/374 [==============================] - 0s 303us/step - loss: 162.3114\n",
      "Epoch 452/1000\n",
      "374/374 [==============================] - 0s 352us/step - loss: 162.1215\n",
      "Epoch 453/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 159.2835\n",
      "Epoch 454/1000\n",
      "374/374 [==============================] - 0s 194us/step - loss: 161.7130\n",
      "Epoch 455/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 160.1241\n",
      "Epoch 456/1000\n",
      "374/374 [==============================] - 0s 233us/step - loss: 161.3449\n",
      "Epoch 457/1000\n",
      "374/374 [==============================] - 0s 314us/step - loss: 165.2512\n",
      "Epoch 458/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 180.0100\n",
      "Epoch 459/1000\n",
      "374/374 [==============================] - 0s 266us/step - loss: 179.7142\n",
      "Epoch 460/1000\n",
      "374/374 [==============================] - 0s 251us/step - loss: 167.0413\n",
      "Epoch 461/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 169.2188\n",
      "Epoch 462/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 160.1064\n",
      "Epoch 463/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 162.6354\n",
      "Epoch 464/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 164.1737\n",
      "Epoch 465/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 162.1837\n",
      "Epoch 466/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 160.4770\n",
      "Epoch 467/1000\n",
      "374/374 [==============================] - 0s 275us/step - loss: 165.2073\n",
      "Epoch 468/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 181.2612\n",
      "Epoch 469/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 161.6135\n",
      "Epoch 470/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 167.1520\n",
      "Epoch 471/1000\n",
      "374/374 [==============================] - 0s 217us/step - loss: 165.7466\n",
      "Epoch 472/1000\n",
      "374/374 [==============================] - 0s 471us/step - loss: 173.5685\n",
      "Epoch 473/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 165.5737\n",
      "Epoch 474/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 168.5431\n",
      "Epoch 475/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 168.0231\n",
      "Epoch 476/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 168.1389\n",
      "Epoch 477/1000\n",
      "374/374 [==============================] - 0s 202us/step - loss: 161.0670\n",
      "Epoch 478/1000\n",
      "374/374 [==============================] - 0s 150us/step - loss: 160.9280\n",
      "Epoch 479/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 164.5733\n",
      "Epoch 480/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 166.8596\n",
      "Epoch 481/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 164.7040\n",
      "Epoch 482/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 162.7126\n",
      "Epoch 483/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 165.7720\n",
      "Epoch 484/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 159.7299\n",
      "Epoch 485/1000\n",
      "374/374 [==============================] - 0s 226us/step - loss: 161.1112\n",
      "Epoch 486/1000\n",
      "374/374 [==============================] - 0s 241us/step - loss: 159.0513\n",
      "Epoch 487/1000\n",
      "374/374 [==============================] - 0s 135us/step - loss: 162.2563\n",
      "Epoch 488/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 160.1707\n",
      "Epoch 489/1000\n",
      "374/374 [==============================] - 0s 166us/step - loss: 162.2133\n",
      "Epoch 490/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 164.1576\n",
      "Epoch 491/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 164.4991\n",
      "Epoch 492/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 161.0852\n",
      "Epoch 493/1000\n",
      "374/374 [==============================] - 0s 263us/step - loss: 160.7636\n",
      "Epoch 494/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 161.7471\n",
      "Epoch 495/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 164.8998\n",
      "Epoch 496/1000\n",
      "374/374 [==============================] - 0s 204us/step - loss: 165.3420\n",
      "Epoch 497/1000\n",
      "374/374 [==============================] - 0s 278us/step - loss: 173.4903\n",
      "Epoch 498/1000\n",
      "374/374 [==============================] - 0s 304us/step - loss: 179.5029\n",
      "Epoch 499/1000\n",
      "374/374 [==============================] - 0s 406us/step - loss: 171.4982\n",
      "Epoch 500/1000\n",
      "374/374 [==============================] - 0s 254us/step - loss: 160.9834\n",
      "Epoch 501/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 163.3662\n",
      "Epoch 502/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 159.9636\n",
      "Epoch 503/1000\n",
      "374/374 [==============================] - 0s 217us/step - loss: 165.7985\n",
      "Epoch 504/1000\n",
      "374/374 [==============================] - 0s 384us/step - loss: 166.6268\n",
      "Epoch 505/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 164.2875\n",
      "Epoch 506/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 164.4004\n",
      "Epoch 507/1000\n",
      "374/374 [==============================] - 0s 166us/step - loss: 162.6477\n",
      "Epoch 508/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 160.5816\n",
      "Epoch 509/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 158.3083\n",
      "Epoch 510/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 159.2928\n",
      "Epoch 511/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 162.9577\n",
      "Epoch 512/1000\n",
      "374/374 [==============================] - 0s 194us/step - loss: 163.5802\n",
      "Epoch 513/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 161.5148\n",
      "Epoch 514/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 159.2229\n",
      "Epoch 515/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 163.7248\n",
      "Epoch 516/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 162.7517\n",
      "Epoch 517/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 161.2941\n",
      "Epoch 518/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 167.7358\n",
      "Epoch 519/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 172.0468\n",
      "Epoch 520/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 176.8497\n",
      "Epoch 521/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 163.1356\n",
      "Epoch 522/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 159.2635\n",
      "Epoch 523/1000\n",
      "374/374 [==============================] - 0s 106us/step - loss: 183.0481\n",
      "Epoch 524/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 173.6988\n",
      "Epoch 525/1000\n",
      "374/374 [==============================] - 0s 253us/step - loss: 173.0238\n",
      "Epoch 526/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 165.5625\n",
      "Epoch 527/1000\n",
      "374/374 [==============================] - 0s 258us/step - loss: 176.9814\n",
      "Epoch 528/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 174.5231\n",
      "Epoch 529/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 165.5085\n",
      "Epoch 530/1000\n",
      "374/374 [==============================] - 0s 202us/step - loss: 169.8085\n",
      "Epoch 531/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 166.9871\n",
      "Epoch 532/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 161.2033\n",
      "Epoch 533/1000\n",
      "374/374 [==============================] - 0s 362us/step - loss: 162.8976\n",
      "Epoch 534/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 161.5189\n",
      "Epoch 535/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 161.3625\n",
      "Epoch 536/1000\n",
      "374/374 [==============================] - 0s 194us/step - loss: 170.5732\n",
      "Epoch 537/1000\n",
      "374/374 [==============================] - 0s 162us/step - loss: 171.0225\n",
      "Epoch 538/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 163.5145\n",
      "Epoch 539/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 165.2606\n",
      "Epoch 540/1000\n",
      "374/374 [==============================] - 0s 226us/step - loss: 163.7391\n",
      "Epoch 541/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 170.0672\n",
      "Epoch 542/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 162.8952\n",
      "Epoch 543/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 160.7151\n",
      "Epoch 544/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 164.3043\n",
      "Epoch 545/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 160.2706\n",
      "Epoch 546/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 159.7927\n",
      "Epoch 547/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 162.6818\n",
      "Epoch 548/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 164.9292\n",
      "Epoch 549/1000\n",
      "374/374 [==============================] - 0s 102us/step - loss: 164.7542\n",
      "Epoch 550/1000\n",
      "374/374 [==============================] - 0s 128us/step - loss: 167.6399\n",
      "Epoch 551/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 182.5346\n",
      "Epoch 552/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 178.8123\n",
      "Epoch 553/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 164.3446\n",
      "Epoch 554/1000\n",
      "374/374 [==============================] - 0s 219us/step - loss: 162.0163\n",
      "Epoch 555/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 170.8843\n",
      "Epoch 556/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 168.0919\n",
      "Epoch 557/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 169.2778\n",
      "Epoch 558/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 161.9004\n",
      "Epoch 559/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 161.4418\n",
      "Epoch 560/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 158.7793\n",
      "Epoch 561/1000\n",
      "374/374 [==============================] - 0s 229us/step - loss: 160.6755\n",
      "Epoch 562/1000\n",
      "374/374 [==============================] - 0s 270us/step - loss: 162.3372\n",
      "Epoch 563/1000\n",
      "374/374 [==============================] - 0s 246us/step - loss: 168.8543\n",
      "Epoch 564/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 165.5566\n",
      "Epoch 565/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 166.5713\n",
      "Epoch 566/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 162.9733\n",
      "Epoch 567/1000\n",
      "374/374 [==============================] - 0s 286us/step - loss: 164.5605\n",
      "Epoch 568/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 160.0464\n",
      "Epoch 569/1000\n",
      "374/374 [==============================] - 0s 139us/step - loss: 159.4634\n",
      "Epoch 570/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 160.8377\n",
      "Epoch 571/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 159.0964\n",
      "Epoch 572/1000\n",
      "374/374 [==============================] - 0s 150us/step - loss: 160.4638\n",
      "Epoch 573/1000\n",
      "374/374 [==============================] - 0s 115us/step - loss: 161.5577\n",
      "Epoch 574/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 176.2491\n",
      "Epoch 575/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 166.7746\n",
      "Epoch 576/1000\n",
      "374/374 [==============================] - 0s 158us/step - loss: 165.2680\n",
      "Epoch 577/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 161.8755\n",
      "Epoch 578/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 162.6444\n",
      "Epoch 579/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 159.9510\n",
      "Epoch 580/1000\n",
      "374/374 [==============================] - 0s 205us/step - loss: 166.5532\n",
      "Epoch 581/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 171.9543\n",
      "Epoch 582/1000\n",
      "374/374 [==============================] - 0s 221us/step - loss: 169.1403\n",
      "Epoch 583/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 159.8703\n",
      "Epoch 584/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 159.9134\n",
      "Epoch 585/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 162.0217\n",
      "Epoch 586/1000\n",
      "374/374 [==============================] - 0s 273us/step - loss: 164.1772\n",
      "Epoch 587/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 159.9365\n",
      "Epoch 588/1000\n",
      "374/374 [==============================] - 0s 106us/step - loss: 161.3240\n",
      "Epoch 589/1000\n",
      "374/374 [==============================] - 0s 263us/step - loss: 169.3448\n",
      "Epoch 590/1000\n",
      "374/374 [==============================] - 0s 197us/step - loss: 164.2632\n",
      "Epoch 591/1000\n",
      "374/374 [==============================] - 0s 226us/step - loss: 158.7704\n",
      "Epoch 592/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 161.8404\n",
      "Epoch 593/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 161.5904\n",
      "Epoch 594/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 160.2755\n",
      "Epoch 595/1000\n",
      "374/374 [==============================] - 0s 119us/step - loss: 163.8368\n",
      "Epoch 596/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 159.7275\n",
      "Epoch 597/1000\n",
      "374/374 [==============================] - 0s 126us/step - loss: 161.5854\n",
      "Epoch 598/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 159.1362\n",
      "Epoch 599/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 163.5520\n",
      "Epoch 600/1000\n",
      "374/374 [==============================] - 0s 140us/step - loss: 159.6315\n",
      "Epoch 601/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 159.9727\n",
      "Epoch 602/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 162.0002\n",
      "Epoch 603/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 159.4037\n",
      "Epoch 604/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 158.0383\n",
      "Epoch 605/1000\n",
      "374/374 [==============================] - 0s 218us/step - loss: 158.9054\n",
      "Epoch 606/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 159.3712\n",
      "Epoch 607/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 159.8412\n",
      "Epoch 608/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 162.9289\n",
      "Epoch 609/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 162.9606\n",
      "Epoch 610/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 167.4478\n",
      "Epoch 611/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 159.8693\n",
      "Epoch 612/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 167.6318\n",
      "Epoch 613/1000\n",
      "374/374 [==============================] - 0s 172us/step - loss: 161.2179\n",
      "Epoch 614/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 158.6706\n",
      "Epoch 615/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 161.2201\n",
      "Epoch 616/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 163.1561\n",
      "Epoch 617/1000\n",
      "374/374 [==============================] - 0s 263us/step - loss: 167.8087\n",
      "Epoch 618/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 162.2771\n",
      "Epoch 619/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 162.2946\n",
      "Epoch 620/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 167.7364\n",
      "Epoch 621/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 161.2318\n",
      "Epoch 622/1000\n",
      "374/374 [==============================] - 0s 68us/step - loss: 160.6415\n",
      "Epoch 623/1000\n",
      "374/374 [==============================] - 0s 231us/step - loss: 166.3489\n",
      "Epoch 624/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 167.1612\n",
      "Epoch 625/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 162.0792\n",
      "Epoch 626/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 165.5682\n",
      "Epoch 627/1000\n",
      "374/374 [==============================] - 0s 136us/step - loss: 161.3043\n",
      "Epoch 628/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 159.4287\n",
      "Epoch 629/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 158.9377\n",
      "Epoch 630/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 167.3541\n",
      "Epoch 631/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 170.1647\n",
      "Epoch 632/1000\n",
      "374/374 [==============================] - 0s 219us/step - loss: 164.1705\n",
      "Epoch 633/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 161.0342\n",
      "Epoch 634/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 163.5193\n",
      "Epoch 635/1000\n",
      "374/374 [==============================] - 0s 210us/step - loss: 166.3254\n",
      "Epoch 636/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 161.2787\n",
      "Epoch 637/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 163.2727\n",
      "Epoch 638/1000\n",
      "374/374 [==============================] - 0s 168us/step - loss: 158.5182\n",
      "Epoch 639/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 161.3274\n",
      "Epoch 640/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 160.2243\n",
      "Epoch 641/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 159.3840\n",
      "Epoch 642/1000\n",
      "374/374 [==============================] - 0s 258us/step - loss: 163.1848\n",
      "Epoch 643/1000\n",
      "374/374 [==============================] - 0s 172us/step - loss: 166.1753\n",
      "Epoch 644/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 166.1809\n",
      "Epoch 645/1000\n",
      "374/374 [==============================] - 0s 266us/step - loss: 162.9587\n",
      "Epoch 646/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 163.8666\n",
      "Epoch 647/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 163.6677\n",
      "Epoch 648/1000\n",
      "374/374 [==============================] - 0s 289us/step - loss: 164.1560\n",
      "Epoch 649/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 162.8195\n",
      "Epoch 650/1000\n",
      "374/374 [==============================] - 0s 265us/step - loss: 164.3533\n",
      "Epoch 651/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 164.2052\n",
      "Epoch 652/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 164.6652\n",
      "Epoch 653/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 164.4812\n",
      "Epoch 654/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 161.6408\n",
      "Epoch 655/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 165.9890\n",
      "Epoch 656/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 160.8594\n",
      "Epoch 657/1000\n",
      "374/374 [==============================] - 0s 115us/step - loss: 161.7437\n",
      "Epoch 658/1000\n",
      "374/374 [==============================] - 0s 156us/step - loss: 159.9010\n",
      "Epoch 659/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 158.2232\n",
      "Epoch 660/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 159.4361\n",
      "Epoch 661/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 162.7344\n",
      "Epoch 662/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 175.3069\n",
      "Epoch 663/1000\n",
      "374/374 [==============================] - 0s 210us/step - loss: 168.8444\n",
      "Epoch 664/1000\n",
      "374/374 [==============================] - 0s 154us/step - loss: 159.1944\n",
      "Epoch 665/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 163.2430\n",
      "Epoch 666/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 164.9573\n",
      "Epoch 667/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 168.2570\n",
      "Epoch 668/1000\n",
      "374/374 [==============================] - 0s 154us/step - loss: 167.2704\n",
      "Epoch 669/1000\n",
      "374/374 [==============================] - 0s 193us/step - loss: 173.4752\n",
      "Epoch 670/1000\n",
      "374/374 [==============================] - 0s 89us/step - loss: 162.4311\n",
      "Epoch 671/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 164.5794\n",
      "Epoch 672/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 164.5824\n",
      "Epoch 673/1000\n",
      "374/374 [==============================] - 0s 75us/step - loss: 160.2349\n",
      "Epoch 674/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 165.3997\n",
      "Epoch 675/1000\n",
      "374/374 [==============================] - 0s 219us/step - loss: 170.7339\n",
      "Epoch 676/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 163.7855\n",
      "Epoch 677/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 169.7072\n",
      "Epoch 678/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 165.0496\n",
      "Epoch 679/1000\n",
      "374/374 [==============================] - 0s 298us/step - loss: 165.3215\n",
      "Epoch 680/1000\n",
      "374/374 [==============================] - 0s 184us/step - loss: 169.3367\n",
      "Epoch 681/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 170.8404\n",
      "Epoch 682/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 163.0741\n",
      "Epoch 683/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 162.4697\n",
      "Epoch 684/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 162.2917\n",
      "Epoch 685/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 169.4800\n",
      "Epoch 686/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 164.1849\n",
      "Epoch 687/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 159.3643\n",
      "Epoch 688/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 159.6885\n",
      "Epoch 689/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 161.1930\n",
      "Epoch 690/1000\n",
      "374/374 [==============================] - 0s 114us/step - loss: 164.4456\n",
      "Epoch 691/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 165.4714\n",
      "Epoch 692/1000\n",
      "374/374 [==============================] - 0s 71us/step - loss: 158.1482\n",
      "Epoch 693/1000\n",
      "374/374 [==============================] - 0s 111us/step - loss: 159.4677\n",
      "Epoch 694/1000\n",
      "374/374 [==============================] - 0s 126us/step - loss: 157.5895\n",
      "Epoch 695/1000\n",
      "374/374 [==============================] - 0s 144us/step - loss: 160.1633\n",
      "Epoch 696/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 157.7689\n",
      "Epoch 697/1000\n",
      "374/374 [==============================] - 0s 135us/step - loss: 168.1410\n",
      "Epoch 698/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 163.5611\n",
      "Epoch 699/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 161.2525\n",
      "Epoch 700/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 161.7464\n",
      "Epoch 701/1000\n",
      "374/374 [==============================] - 0s 209us/step - loss: 176.0836\n",
      "Epoch 702/1000\n",
      "374/374 [==============================] - 0s 168us/step - loss: 169.6368\n",
      "Epoch 703/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 165.5673\n",
      "Epoch 704/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 167.1029\n",
      "Epoch 705/1000\n",
      "374/374 [==============================] - 0s 170us/step - loss: 167.7145\n",
      "Epoch 706/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 163.2407\n",
      "Epoch 707/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 170.4375\n",
      "Epoch 708/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 159.0279\n",
      "Epoch 709/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 159.1998\n",
      "Epoch 710/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 160.4324\n",
      "Epoch 711/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 161.0409\n",
      "Epoch 712/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 159.7007\n",
      "Epoch 713/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 160.0399\n",
      "Epoch 714/1000\n",
      "374/374 [==============================] - 0s 140us/step - loss: 162.2268\n",
      "Epoch 715/1000\n",
      "374/374 [==============================] - 0s 135us/step - loss: 166.2961\n",
      "Epoch 716/1000\n",
      "374/374 [==============================] - 0s 131us/step - loss: 165.4255\n",
      "Epoch 717/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 169.8651\n",
      "Epoch 718/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 167.4397\n",
      "Epoch 719/1000\n",
      "374/374 [==============================] - 0s 129us/step - loss: 169.5417\n",
      "Epoch 720/1000\n",
      "374/374 [==============================] - 0s 271us/step - loss: 164.4365\n",
      "Epoch 721/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 167.3329\n",
      "Epoch 722/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 162.6441\n",
      "Epoch 723/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 159.2065\n",
      "Epoch 724/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 160.6218\n",
      "Epoch 725/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 165.3065\n",
      "Epoch 726/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 167.2884\n",
      "Epoch 727/1000\n",
      "374/374 [==============================] - 0s 116us/step - loss: 165.5382\n",
      "Epoch 728/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 176.8126\n",
      "Epoch 729/1000\n",
      "374/374 [==============================] - 0s 116us/step - loss: 167.3025\n",
      "Epoch 730/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 166.3492\n",
      "Epoch 731/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 173.4286\n",
      "Epoch 732/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 162.1662\n",
      "Epoch 733/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 162.6176\n",
      "Epoch 734/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 159.1249\n",
      "Epoch 735/1000\n",
      "374/374 [==============================] - 0s 189us/step - loss: 160.7009\n",
      "Epoch 736/1000\n",
      "374/374 [==============================] - 0s 120us/step - loss: 161.1542\n",
      "Epoch 737/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 162.9813\n",
      "Epoch 738/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 161.7921\n",
      "Epoch 739/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 158.7490\n",
      "Epoch 740/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 158.6003\n",
      "Epoch 741/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 160.3182\n",
      "Epoch 742/1000\n",
      "374/374 [==============================] - 0s 120us/step - loss: 168.4163\n",
      "Epoch 743/1000\n",
      "374/374 [==============================] - 0s 96us/step - loss: 165.4495\n",
      "Epoch 744/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 165.4844\n",
      "Epoch 745/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 168.8114\n",
      "Epoch 746/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 159.9950\n",
      "Epoch 747/1000\n",
      "374/374 [==============================] - 0s 120us/step - loss: 165.4990\n",
      "Epoch 748/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 176.4565\n",
      "Epoch 749/1000\n",
      "374/374 [==============================] - 0s 158us/step - loss: 170.4575\n",
      "Epoch 750/1000\n",
      "374/374 [==============================] - 0s 229us/step - loss: 159.5781\n",
      "Epoch 751/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 158.3592\n",
      "Epoch 752/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 161.8134\n",
      "Epoch 753/1000\n",
      "374/374 [==============================] - 0s 249us/step - loss: 161.2135\n",
      "Epoch 754/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 160.9725\n",
      "Epoch 755/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 162.9123\n",
      "Epoch 756/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 160.0358\n",
      "Epoch 757/1000\n",
      "374/374 [==============================] - 0s 258us/step - loss: 165.9638\n",
      "Epoch 758/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 162.4907\n",
      "Epoch 759/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 163.7860\n",
      "Epoch 760/1000\n",
      "374/374 [==============================] - 0s 254us/step - loss: 164.3896\n",
      "Epoch 761/1000\n",
      "374/374 [==============================] - 0s 321us/step - loss: 159.9212\n",
      "Epoch 762/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 160.9565\n",
      "Epoch 763/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 170.8668\n",
      "Epoch 764/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 171.4610\n",
      "Epoch 765/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 157.9397\n",
      "Epoch 766/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 159.9001\n",
      "Epoch 767/1000\n",
      "374/374 [==============================] - 0s 143us/step - loss: 162.0980\n",
      "Epoch 768/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 167.3298\n",
      "Epoch 769/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 163.1843\n",
      "Epoch 770/1000\n",
      "374/374 [==============================] - 0s 175us/step - loss: 161.6693\n",
      "Epoch 771/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 166.1077\n",
      "Epoch 772/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 163.9843\n",
      "Epoch 773/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 158.0514\n",
      "Epoch 774/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 157.7313\n",
      "Epoch 775/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 158.9028\n",
      "Epoch 776/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 161.2296\n",
      "Epoch 777/1000\n",
      "374/374 [==============================] - 0s 401us/step - loss: 165.9814\n",
      "Epoch 778/1000\n",
      "374/374 [==============================] - 0s 212us/step - loss: 172.9910\n",
      "Epoch 779/1000\n",
      "374/374 [==============================] - 0s 246us/step - loss: 162.6530\n",
      "Epoch 780/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 166.6625\n",
      "Epoch 781/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 159.0242\n",
      "Epoch 782/1000\n",
      "374/374 [==============================] - 0s 226us/step - loss: 172.6585\n",
      "Epoch 783/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 176.8083\n",
      "Epoch 784/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 170.8407\n",
      "Epoch 785/1000\n",
      "374/374 [==============================] - 0s 75us/step - loss: 161.5478\n",
      "Epoch 786/1000\n",
      "374/374 [==============================] - 0s 278us/step - loss: 174.6266\n",
      "Epoch 787/1000\n",
      "374/374 [==============================] - 0s 245us/step - loss: 166.4352\n",
      "Epoch 788/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 168.9656\n",
      "Epoch 789/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 164.5325\n",
      "Epoch 790/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 164.1997\n",
      "Epoch 791/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 177.7714\n",
      "Epoch 792/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 165.9754\n",
      "Epoch 793/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 159.0455\n",
      "Epoch 794/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 169.1125\n",
      "Epoch 795/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 170.6039\n",
      "Epoch 796/1000\n",
      "374/374 [==============================] - 0s 144us/step - loss: 161.8005\n",
      "Epoch 797/1000\n",
      "374/374 [==============================] - 0s 154us/step - loss: 159.0024\n",
      "Epoch 798/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 161.0408\n",
      "Epoch 799/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 161.3515\n",
      "Epoch 800/1000\n",
      "374/374 [==============================] - 0s 198us/step - loss: 163.9098\n",
      "Epoch 801/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 164.8839\n",
      "Epoch 802/1000\n",
      "374/374 [==============================] - 0s 174us/step - loss: 159.2119\n",
      "Epoch 803/1000\n",
      "374/374 [==============================] - 0s 83us/step - loss: 160.7829\n",
      "Epoch 804/1000\n",
      "374/374 [==============================] - 0s 140us/step - loss: 167.4168\n",
      "Epoch 805/1000\n",
      "374/374 [==============================] - 0s 200us/step - loss: 165.1234\n",
      "Epoch 806/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 158.6710\n",
      "Epoch 807/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 159.2316\n",
      "Epoch 808/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 161.6161\n",
      "Epoch 809/1000\n",
      "374/374 [==============================] - 0s 95us/step - loss: 164.8346\n",
      "Epoch 810/1000\n",
      "374/374 [==============================] - 0s 214us/step - loss: 169.3714\n",
      "Epoch 811/1000\n",
      "374/374 [==============================] - 0s 448us/step - loss: 174.3917\n",
      "Epoch 812/1000\n",
      "374/374 [==============================] - 0s 206us/step - loss: 168.8294\n",
      "Epoch 813/1000\n",
      "374/374 [==============================] - 0s 74us/step - loss: 165.6892\n",
      "Epoch 814/1000\n",
      "374/374 [==============================] - 0s 257us/step - loss: 168.1389\n",
      "Epoch 815/1000\n",
      "374/374 [==============================] - 0s 229us/step - loss: 160.9772\n",
      "Epoch 816/1000\n",
      "374/374 [==============================] - 0s 168us/step - loss: 163.2282\n",
      "Epoch 817/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 159.9772\n",
      "Epoch 818/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 158.1791\n",
      "Epoch 819/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 156.8821\n",
      "Epoch 820/1000\n",
      "374/374 [==============================] - 0s 132us/step - loss: 159.5893\n",
      "Epoch 821/1000\n",
      "374/374 [==============================] - 0s 242us/step - loss: 162.8636\n",
      "Epoch 822/1000\n",
      "374/374 [==============================] - 0s 140us/step - loss: 170.0257\n",
      "Epoch 823/1000\n",
      "374/374 [==============================] - 0s 128us/step - loss: 178.6022\n",
      "Epoch 824/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 171.6882\n",
      "Epoch 825/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 162.5235\n",
      "Epoch 826/1000\n",
      "374/374 [==============================] - 0s 202us/step - loss: 164.8368\n",
      "Epoch 827/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 158.8205\n",
      "Epoch 828/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 171.6465\n",
      "Epoch 829/1000\n",
      "374/374 [==============================] - 0s 314us/step - loss: 178.0608\n",
      "Epoch 830/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 173.3991\n",
      "Epoch 831/1000\n",
      "374/374 [==============================] - 0s 170us/step - loss: 182.2766\n",
      "Epoch 832/1000\n",
      "374/374 [==============================] - 0s 188us/step - loss: 166.0202\n",
      "Epoch 833/1000\n",
      "374/374 [==============================] - 0s 148us/step - loss: 162.9905\n",
      "Epoch 834/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 159.3788\n",
      "Epoch 835/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 158.5383\n",
      "Epoch 836/1000\n",
      "374/374 [==============================] - 0s 78us/step - loss: 162.8014\n",
      "Epoch 837/1000\n",
      "374/374 [==============================] - 0s 154us/step - loss: 172.8627\n",
      "Epoch 838/1000\n",
      "374/374 [==============================] - 0s 263us/step - loss: 164.2311\n",
      "Epoch 839/1000\n",
      "374/374 [==============================] - 0s 278us/step - loss: 161.5516\n",
      "Epoch 840/1000\n",
      "374/374 [==============================] - 0s 87us/step - loss: 162.7464\n",
      "Epoch 841/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 160.1869\n",
      "Epoch 842/1000\n",
      "374/374 [==============================] - 0s 290us/step - loss: 159.0055\n",
      "Epoch 843/1000\n",
      "374/374 [==============================] - 0s 74us/step - loss: 166.6945\n",
      "Epoch 844/1000\n",
      "374/374 [==============================] - 0s 353us/step - loss: 166.5742\n",
      "Epoch 845/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 164.9887\n",
      "Epoch 846/1000\n",
      "374/374 [==============================] - 0s 254us/step - loss: 159.7124\n",
      "Epoch 847/1000\n",
      "374/374 [==============================] - 0s 160us/step - loss: 158.8030\n",
      "Epoch 848/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 164.2228\n",
      "Epoch 849/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 161.2727\n",
      "Epoch 850/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 159.2209\n",
      "Epoch 851/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 160.5294\n",
      "Epoch 852/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 157.2053\n",
      "Epoch 853/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 160.4073\n",
      "Epoch 854/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 169.3605\n",
      "Epoch 855/1000\n",
      "374/374 [==============================] - 0s 123us/step - loss: 165.7371\n",
      "Epoch 856/1000\n",
      "374/374 [==============================] - 0s 80us/step - loss: 168.6374\n",
      "Epoch 857/1000\n",
      "374/374 [==============================] - 0s 166us/step - loss: 164.2721\n",
      "Epoch 858/1000\n",
      "374/374 [==============================] - 0s 134us/step - loss: 160.2879\n",
      "Epoch 859/1000\n",
      "374/374 [==============================] - 0s 108us/step - loss: 157.7921\n",
      "Epoch 860/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 160.3571\n",
      "Epoch 861/1000\n",
      "374/374 [==============================] - 0s 253us/step - loss: 164.9603\n",
      "Epoch 862/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 164.6722\n",
      "Epoch 863/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 166.3557\n",
      "Epoch 864/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 161.5077\n",
      "Epoch 865/1000\n",
      "374/374 [==============================] - 0s 138us/step - loss: 159.0600\n",
      "Epoch 866/1000\n",
      "374/374 [==============================] - 0s 99us/step - loss: 160.2310\n",
      "Epoch 867/1000\n",
      "374/374 [==============================] - 0s 188us/step - loss: 157.9307\n",
      "Epoch 868/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 160.5528\n",
      "Epoch 869/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 167.9961\n",
      "Epoch 870/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 178.6187\n",
      "Epoch 871/1000\n",
      "374/374 [==============================] - 0s 147us/step - loss: 164.8990\n",
      "Epoch 872/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 174.5878\n",
      "Epoch 873/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 164.2481\n",
      "Epoch 874/1000\n",
      "374/374 [==============================] - 0s 207us/step - loss: 159.0086\n",
      "Epoch 875/1000\n",
      "374/374 [==============================] - 0s 151us/step - loss: 163.5849\n",
      "Epoch 876/1000\n",
      "374/374 [==============================] - 0s 139us/step - loss: 159.9690\n",
      "Epoch 877/1000\n",
      "374/374 [==============================] - 0s 142us/step - loss: 159.6047\n",
      "Epoch 878/1000\n",
      "374/374 [==============================] - 0s 110us/step - loss: 163.2561\n",
      "Epoch 879/1000\n",
      "374/374 [==============================] - 0s 130us/step - loss: 163.2348\n",
      "Epoch 880/1000\n",
      "374/374 [==============================] - 0s 171us/step - loss: 159.7770\n",
      "Epoch 881/1000\n",
      "374/374 [==============================] - 0s 70us/step - loss: 160.7964\n",
      "Epoch 882/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 163.7806\n",
      "Epoch 883/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 170.8374\n",
      "Epoch 884/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 164.7362\n",
      "Epoch 885/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 164.2650\n",
      "Epoch 886/1000\n",
      "374/374 [==============================] - 0s 166us/step - loss: 174.6766\n",
      "Epoch 887/1000\n",
      "374/374 [==============================] - 0s 78us/step - loss: 158.8235\n",
      "Epoch 888/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 163.4770\n",
      "Epoch 889/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 161.1920\n",
      "Epoch 890/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 158.8272\n",
      "Epoch 891/1000\n",
      "374/374 [==============================] - 0s 249us/step - loss: 162.4693\n",
      "Epoch 892/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 162.5828\n",
      "Epoch 893/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 156.9820\n",
      "Epoch 894/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 162.3271\n",
      "Epoch 895/1000\n",
      "374/374 [==============================] - 0s 122us/step - loss: 158.9057\n",
      "Epoch 896/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 160.5272\n",
      "Epoch 897/1000\n",
      "374/374 [==============================] - 0s 227us/step - loss: 166.1752\n",
      "Epoch 898/1000\n",
      "374/374 [==============================] - 0s 146us/step - loss: 157.5687\n",
      "Epoch 899/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 161.6465\n",
      "Epoch 900/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 166.3187\n",
      "Epoch 901/1000\n",
      "374/374 [==============================] - 0s 158us/step - loss: 162.9832\n",
      "Epoch 902/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 158.0223\n",
      "Epoch 903/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 159.1388\n",
      "Epoch 904/1000\n",
      "374/374 [==============================] - 0s 88us/step - loss: 163.7649\n",
      "Epoch 905/1000\n",
      "374/374 [==============================] - 0s 82us/step - loss: 159.6924\n",
      "Epoch 906/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 156.7638\n",
      "Epoch 907/1000\n",
      "374/374 [==============================] - 0s 151us/step - loss: 157.6551\n",
      "Epoch 908/1000\n",
      "374/374 [==============================] - 0s 124us/step - loss: 161.3770\n",
      "Epoch 909/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 163.9658\n",
      "Epoch 910/1000\n",
      "374/374 [==============================] - 0s 283us/step - loss: 171.6603\n",
      "Epoch 911/1000\n",
      "374/374 [==============================] - 0s 291us/step - loss: 164.4381\n",
      "Epoch 912/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 163.9323\n",
      "Epoch 913/1000\n",
      "374/374 [==============================] - 0s 172us/step - loss: 159.6305\n",
      "Epoch 914/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 162.1845\n",
      "Epoch 915/1000\n",
      "374/374 [==============================] - 0s 72us/step - loss: 162.8553\n",
      "Epoch 916/1000\n",
      "374/374 [==============================] - 0s 118us/step - loss: 163.3559\n",
      "Epoch 917/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 165.2089\n",
      "Epoch 918/1000\n",
      "374/374 [==============================] - 0s 91us/step - loss: 169.5147\n",
      "Epoch 919/1000\n",
      "374/374 [==============================] - 0s 219us/step - loss: 165.5529\n",
      "Epoch 920/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 157.5948\n",
      "Epoch 921/1000\n",
      "374/374 [==============================] - 0s 148us/step - loss: 160.6199\n",
      "Epoch 922/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 171.6728\n",
      "Epoch 923/1000\n",
      "374/374 [==============================] - 0s 201us/step - loss: 168.6433\n",
      "Epoch 924/1000\n",
      "374/374 [==============================] - 0s 112us/step - loss: 167.4563\n",
      "Epoch 925/1000\n",
      "374/374 [==============================] - 0s 74us/step - loss: 161.3775\n",
      "Epoch 926/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 160.9774\n",
      "Epoch 927/1000\n",
      "374/374 [==============================] - 0s 167us/step - loss: 167.7306\n",
      "Epoch 928/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 159.9786\n",
      "Epoch 929/1000\n",
      "374/374 [==============================] - 0s 178us/step - loss: 166.8689\n",
      "Epoch 930/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 172.6099\n",
      "Epoch 931/1000\n",
      "374/374 [==============================] - 0s 104us/step - loss: 174.4843\n",
      "Epoch 932/1000\n",
      "374/374 [==============================] - 0s 98us/step - loss: 176.9528\n",
      "Epoch 933/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 166.0943\n",
      "Epoch 934/1000\n",
      "374/374 [==============================] - 0s 223us/step - loss: 170.8084\n",
      "Epoch 935/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 168.2883\n",
      "Epoch 936/1000\n",
      "374/374 [==============================] - 0s 202us/step - loss: 174.1376\n",
      "Epoch 937/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 169.0385\n",
      "Epoch 938/1000\n",
      "374/374 [==============================] - 0s 195us/step - loss: 172.9150\n",
      "Epoch 939/1000\n",
      "374/374 [==============================] - 0s 188us/step - loss: 164.9994\n",
      "Epoch 940/1000\n",
      "374/374 [==============================] - 0s 166us/step - loss: 162.3078\n",
      "Epoch 941/1000\n",
      "374/374 [==============================] - 0s 103us/step - loss: 158.5138\n",
      "Epoch 942/1000\n",
      "374/374 [==============================] - 0s 183us/step - loss: 164.5309\n",
      "Epoch 943/1000\n",
      "374/374 [==============================] - 0s 265us/step - loss: 164.1639\n",
      "Epoch 944/1000\n",
      "374/374 [==============================] - 0s 76us/step - loss: 156.4428\n",
      "Epoch 945/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 159.3554\n",
      "Epoch 946/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 157.4736\n",
      "Epoch 947/1000\n",
      "374/374 [==============================] - 0s 84us/step - loss: 160.5560\n",
      "Epoch 948/1000\n",
      "374/374 [==============================] - 0s 317us/step - loss: 170.8225\n",
      "Epoch 949/1000\n",
      "374/374 [==============================] - 0s 79us/step - loss: 178.6027\n",
      "Epoch 950/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 165.3603\n",
      "Epoch 951/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 165.7648\n",
      "Epoch 952/1000\n",
      "374/374 [==============================] - 0s 213us/step - loss: 163.1199\n",
      "Epoch 953/1000\n",
      "374/374 [==============================] - 0s 86us/step - loss: 159.5391\n",
      "Epoch 954/1000\n",
      "374/374 [==============================] - 0s 237us/step - loss: 159.0592\n",
      "Epoch 955/1000\n",
      "374/374 [==============================] - 0s 135us/step - loss: 165.5485\n",
      "Epoch 956/1000\n",
      "374/374 [==============================] - 0s 127us/step - loss: 164.9222\n",
      "Epoch 957/1000\n",
      "374/374 [==============================] - 0s 127us/step - loss: 158.6284\n",
      "Epoch 958/1000\n",
      "374/374 [==============================] - 0s 180us/step - loss: 160.7212\n",
      "Epoch 959/1000\n",
      "374/374 [==============================] - 0s 127us/step - loss: 157.9159\n",
      "Epoch 960/1000\n",
      "374/374 [==============================] - 0s 187us/step - loss: 158.5595\n",
      "Epoch 961/1000\n",
      "374/374 [==============================] - 0s 234us/step - loss: 160.7167\n",
      "Epoch 962/1000\n",
      "374/374 [==============================] - 0s 100us/step - loss: 163.2740\n",
      "Epoch 963/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 157.4702\n",
      "Epoch 964/1000\n",
      "374/374 [==============================] - 0s 143us/step - loss: 161.5624\n",
      "Epoch 965/1000\n",
      "374/374 [==============================] - 0s 211us/step - loss: 159.8765\n",
      "Epoch 966/1000\n",
      "374/374 [==============================] - 0s 235us/step - loss: 168.4229\n",
      "Epoch 967/1000\n",
      "374/374 [==============================] - 0s 119us/step - loss: 174.5279\n",
      "Epoch 968/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 164.1903\n",
      "Epoch 969/1000\n",
      "374/374 [==============================] - 0s 233us/step - loss: 163.3802\n",
      "Epoch 970/1000\n",
      "374/374 [==============================] - 0s 246us/step - loss: 158.4161\n",
      "Epoch 971/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 163.7835\n",
      "Epoch 972/1000\n",
      "374/374 [==============================] - 0s 107us/step - loss: 158.5077\n",
      "Epoch 973/1000\n",
      "374/374 [==============================] - 0s 287us/step - loss: 157.9272\n",
      "Epoch 974/1000\n",
      "374/374 [==============================] - 0s 215us/step - loss: 166.0508\n",
      "Epoch 975/1000\n",
      "374/374 [==============================] - 0s 230us/step - loss: 163.7461\n",
      "Epoch 976/1000\n",
      "374/374 [==============================] - 0s 238us/step - loss: 160.9972\n",
      "Epoch 977/1000\n",
      "374/374 [==============================] - 0s 222us/step - loss: 162.5770\n",
      "Epoch 978/1000\n",
      "374/374 [==============================] - 0s 92us/step - loss: 159.9763\n",
      "Epoch 979/1000\n",
      "374/374 [==============================] - 0s 199us/step - loss: 156.8934\n",
      "Epoch 980/1000\n",
      "374/374 [==============================] - 0s 295us/step - loss: 159.5617\n",
      "Epoch 981/1000\n",
      "374/374 [==============================] - 0s 275us/step - loss: 160.5603\n",
      "Epoch 982/1000\n",
      "374/374 [==============================] - 0s 221us/step - loss: 161.4734\n",
      "Epoch 983/1000\n",
      "374/374 [==============================] - 0s 179us/step - loss: 157.8208\n",
      "Epoch 984/1000\n",
      "374/374 [==============================] - 0s 114us/step - loss: 158.1310\n",
      "Epoch 985/1000\n",
      "374/374 [==============================] - 0s 191us/step - loss: 158.4417\n",
      "Epoch 986/1000\n",
      "374/374 [==============================] - 0s 186us/step - loss: 160.4298\n",
      "Epoch 987/1000\n",
      "374/374 [==============================] - 0s 190us/step - loss: 163.9759\n",
      "Epoch 988/1000\n",
      "374/374 [==============================] - 0s 262us/step - loss: 159.1354\n",
      "Epoch 989/1000\n",
      "374/374 [==============================] - 0s 101us/step - loss: 160.1212\n",
      "Epoch 990/1000\n",
      "374/374 [==============================] - 0s 90us/step - loss: 160.5440\n",
      "Epoch 991/1000\n",
      "374/374 [==============================] - 0s 203us/step - loss: 161.8526\n",
      "Epoch 992/1000\n",
      "374/374 [==============================] - 0s 269us/step - loss: 160.2719\n",
      "Epoch 993/1000\n",
      "374/374 [==============================] - 0s 221us/step - loss: 159.2598\n",
      "Epoch 994/1000\n",
      "374/374 [==============================] - 0s 176us/step - loss: 162.9057\n",
      "Epoch 995/1000\n",
      "374/374 [==============================] - 0s 94us/step - loss: 172.1639\n",
      "Epoch 996/1000\n",
      "374/374 [==============================] - 0s 182us/step - loss: 169.5340\n",
      "Epoch 997/1000\n",
      "374/374 [==============================] - 0s 285us/step - loss: 159.0620\n",
      "Epoch 998/1000\n",
      "374/374 [==============================] - 0s 309us/step - loss: 162.3736\n",
      "Epoch 999/1000\n",
      "374/374 [==============================] - 0s 225us/step - loss: 164.4068\n",
      "Epoch 1000/1000\n",
      "374/374 [==============================] - 0s 163us/step - loss: 166.5204\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X0, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 233.67108154,  234.75735474,  236.18276978],\n",
       "       [ 230.00267029,  230.28271484,  230.40301514],\n",
       "       [ 228.28158569,  224.78652954,  225.02078247],\n",
       "       ..., \n",
       "       [ 229.89108276,  228.58634949,  228.44515991],\n",
       "       [ 230.08216858,  230.11611938,  230.41091919],\n",
       "       [ 235.25253296,  229.90315247,  230.97879028]], dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_39_input to have 2 dimensions, but got array with shape (1, 2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-283-5ecf1f7b35fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_color\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolor1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcolor_3_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_color\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolor1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1025\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected dense_39_input to have 2 dimensions, but got array with shape (1, 2, 3)"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    input_color = np.vstack([color1[idx], color2[idx]])[np.newaxis, :, :]\n",
    "    color_3_pre = model1.predict(input_color)[0]\n",
    "\n",
    "    true = [color1[idx], color2[idx], color3[idx]]\n",
    "    predict = [color1[idx], color2[idx], color_3_pre]\n",
    "    \n",
    "    bar_true = plot_colors([0.33, 0.33, 0.33], true, h=50, w=300)\n",
    "    bar_predict = plot_colors([0.33, 0.33, 0.33], predict, h=50, w=300)\n",
    "    \n",
    "    plt.figure(figsize = (5, 1))  \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(bar_true)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(bar_predict)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import lightgbmregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
